import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix


# --- 1. DATA LOADING & PREPARATION ---
def load_and_prepare_data(file_path):
    df = pd.read_csv(file_path)

    # Selecting the best predictors found in Week 2 EDA
    features = ['Age', 'Application_Delay_Days', 'Opportunity_Duration_Days', 'Application_Month',
                'Opportunity Category', 'Country_Grouped', 'Gender']
    target = 'Success_Binary'

    # Handle Missing Values (Imputation)
    df['Application_Delay_Days'] = df['Application_Delay_Days'].fillna(df['Application_Delay_Days'].median())
    df['Application_Month'] = df['Application_Month'].fillna(df['Application_Month'].mode()[0])

    # Encoding Categorical Variables (Converting text to numbers)
    X = pd.get_dummies(df[features], drop_first=True)
    y = df[target]

    return train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)


# --- 2. MODEL BUILDING & EVALUATION ---
def train_and_evaluate(X_train, X_test, y_train, y_test):
    # Scale numerical features for Logistic Regression
    scaler = StandardScaler()
    cols_to_scale = ['Age', 'Application_Delay_Days', 'Opportunity_Duration_Days', 'Application_Month']
    X_train_scaled = X_train.copy()
    X_test_scaled = X_test.copy()
    X_train_scaled[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])
    X_test_scaled[cols_to_scale] = scaler.transform(X_test[cols_to_scale])

    models = {
        "Logistic Regression": LogisticRegression(max_iter=1000),
        "Decision Tree": DecisionTreeClassifier(random_state=42),
        "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42)
    }

    performance_results = []

    for name, model in models.items():
        # Use scaled data for Logistic Regression, raw data for Tree models
        current_X_train = X_train_scaled if name == "Logistic Regression" else X_train
        current_X_test = X_test_scaled if name == "Logistic Regression" else X_test

        model.fit(current_X_train, y_train)
        y_pred = model.predict(current_X_test)

        performance_results.append({
            "Model": name,
            "Accuracy": accuracy_score(y_test, y_pred),
            "Precision": precision_score(y_test, y_pred),
            "Recall": recall_score(y_test, y_pred),
            "F1-Score": f1_score(y_test, y_pred)
        })

    # --- 3. CHURN FACTOR ANALYSIS (Feature Importance) ---
    rf_model = models["Random Forest"]
    feat_importances = pd.Series(rf_model.feature_importances_, index=X_train.columns)

    # Plotting Feature Importance
    plt.figure(figsize=(10, 6))
    feat_importances.nlargest(10).plot(kind='barh', color='teal')
    plt.title('Top 10 Factors Influencing Student Success (Churn Analysis)')
    plt.xlabel('Importance Score')
    plt.tight_layout()
    plt.savefig('feature_importance_week3.png')

    return pd.DataFrame(performance_results), rf_model


# --- MAIN EXECUTION ---
if __name__ == "__main__":
    PATH = r"C:\Users\Administrator\Downloads\SLU_Opportunity_Wise_Data_CLEANED.csv"

    try:
        X_train, X_test, y_train, y_test = load_and_prepare_data(PATH)
        results, final_model = train_and_evaluate(X_train, X_test, y_train, y_test)

        print("\n--- Model Performance Metrics ---")
        print(results)
        print("\nSUCCESS: Model trained and 'feature_importance_week3.png' saved.")
    except FileNotFoundError:
        print("Error: Please check your FILE_PATH.")
